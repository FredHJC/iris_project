{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "iris_update.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "XWnAg0aEd3C8"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jXfuyRInkyyj"
   },
   "source": [
    "#  !pip install unrar\n",
    "#  !unrar x CASIA.rar"
   ],
   "execution_count": 174,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cUSDxdXEAt8G"
   },
   "source": [
    "# def IrisLocalization(images):\n",
    "#     # Convert all images to grayscale first\n",
    "#     images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "#     # Create empty lists to store boundary and center\n",
    "#     boundary = []\n",
    "#     center = []\n",
    "        \n",
    "    \n",
    "#     for img in images:\n",
    "#         # Blurring the image\n",
    "#         blurred = cv2.bilateralFilter(img,9,80,80)\n",
    "#         img = blurred\n",
    "\n",
    "\n",
    "#         # Estimating the center of the image\n",
    "#         horizontal_mean = np.mean(img,axis = 0)\n",
    "#         vertical_mean = np.mean(img,axis = 1)\n",
    "#         # The indices with the min values\n",
    "#         X_p = horizontal_mean.argmin()\n",
    "#         Y_p = vertical_mean.argmin()\n",
    "\n",
    "#         # Create a 120 * 120 region centered at the (X_p,Y_p)\n",
    "#         circle_x = img[X_p-60:X_p+60]\n",
    "#         circle_y = img[Y_p-60:Y_p+60]\n",
    "\n",
    "#         # Update the center and estimate center of the pupil\n",
    "#         horizontal_mean = np.mean(circle_y,axis = 0)\n",
    "#         vertical_mean = np.mean(circle_x,axis = 0)\n",
    "\n",
    "#         # Center of the 120*120 region\n",
    "#         xp = horizontal_mean.argmin()\n",
    "#         yp = vertical_mean.argmin()\n",
    "#         # Define center of the pupil\n",
    "#         pupil_center = (xp,yp)\n",
    "\n",
    "#         copy_img = img.copy()\n",
    "#         # Locate the pupil center and show it on the image with one point\n",
    "#         cv2.circle(copy_img,(xp,yp),1,(255,0,0),2)\n",
    "\n",
    "#         # Setting threshold\n",
    "#         masked_img = cv2.inRange(img,0,70)\n",
    "#         result = cv2.bitwise_and(img,masked_img)\n",
    "#         # Apply Canny detector on masked image\n",
    "#         img_edge = cv2.Canny(result, 100, 200)\n",
    "\n",
    "#         # Apply Hough transform to the edged image\n",
    "#         circle = cv2.HoughCircles(img_edge, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "\n",
    "#         min_dist = math.inf\n",
    "#         for i in range(len(circle[0])):\n",
    "\n",
    "#             c=(circle[0][i][0],circle[0][i][1])\n",
    "#             dist = distance.euclidean(pupil_center, c)\n",
    "#             if dist < min_dist:\n",
    "#                 min_dist = dist\n",
    "#                 k = circle[0][i]\n",
    "\n",
    "#         img_orig = img.copy()\n",
    "#         # Draw the inner boundary\n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), int(k[2]), (255, 0, 0), 2)\n",
    "\n",
    "#         pupil = k\n",
    "#         radius_pupil = int(k[2])\n",
    "\n",
    "#         # Draw the outer boundary, with the inner boundary adding about 55-60 depending on different people  \n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), radius_pupil+55, (255, 0, 0), 2)\n",
    "\n",
    "#         # plt.imshow(img_orig,cmap='gray')\n",
    "#         boundary.append(img_orig)\n",
    "#         center.append([int(k[0]),int(k[1]),int(k[2])])\n",
    "#     return boundary,center"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ToH4mp86erIL"
   },
   "source": [
    "# def normalization(data, target_array):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     def map_element(idx):\n",
    "#       X, Y = idx[0], idx[1]\n",
    "#       # print(idx)\n",
    "#       # print(X, Y)\n",
    "\n",
    "#       theta = 2 * np.pi * X/N\n",
    "#       # adjacent side for pupil and iris \n",
    "#       adj_p = np.cos(theta) * radius_pupil\n",
    "#       adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#       # opoosite side for pupil and iris\n",
    "#       oppo_p = np.sin(theta) * radius_pupil\n",
    "#       oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#       # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#       x_p = int(np.round(x_pupil + adj_p))\n",
    "#       y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#       # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#       x_i = int(np.round(x_pupil + adj_i))\n",
    "#       y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#       # x & y (new projection) from equation\n",
    "#       x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#       y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#       # x & y should not exceed image boundary i.e(320,280)\n",
    "#       if y >= 320:\n",
    "#           y = 319\n",
    "#       if x >= 280:\n",
    "#           x = 279\n",
    "#       return img[x, y]\n",
    "\n",
    "\n",
    "#     # print(rows.shape)\n",
    "#     myfunc_vec = np.vectorize(map_element)\n",
    "#     normalized = myfunc_vec(target_array)\n",
    "#     return normalized\n",
    "#     #return normalized"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sevoDNwKxTyo"
   },
   "source": [
    "# def normalization(data):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     normalized = []\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     M = 64\n",
    "#     N = 512\n",
    "\n",
    "#     for Y in range(M):\n",
    "#         row_pix = []\n",
    "        \n",
    "#         for X in range(N):\n",
    "#             theta = 2 * np.pi * X/N\n",
    "#             # adjacent side for pupil and iris \n",
    "#             adj_p = np.cos(theta) * radius_pupil\n",
    "#             adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#             # opoosite side for pupil and iris\n",
    "#             oppo_p = np.sin(theta) * radius_pupil\n",
    "#             oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#             # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#             x_p = int(np.round(x_pupil + adj_p))\n",
    "#             y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#             # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#             x_i = int(np.round(x_pupil + adj_i))\n",
    "#             y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#             # x & y (new projection) from equation\n",
    "#             x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#             y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#             # x & y should not exceed image boundary i.e(320,280)\n",
    "#             if y >= 320:\n",
    "#                 y = 319\n",
    "#             if x >= 280:\n",
    "#                 x = 279\n",
    "    \n",
    "#             row_pix.append(img[x, y])\n",
    "#         normalized.append(np.array(row_pix))\n",
    "\n",
    "#     return ImageEnhancement(np.array(normalized))\n",
    "#     #return normalized"
   ],
   "execution_count": 72,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PeeHHQYAFi-7"
   },
   "source": [
    "# def ImageEnhancement(normalized):\n",
    " \n",
    "#     enhanced_normal = normalized.copy()\n",
    "\n",
    "#     # range for row and column\n",
    "#     nrow = int(normalized.shape[0]/32) # 2\n",
    "#     ncol = int(normalized.shape[1]/32) # 16\n",
    "\n",
    "#     # The following loop will first define each 32*32 region in normalized image\n",
    "#     # and then perform histogram equalization in each divided region\n",
    "    \n",
    "#     for row in range(nrow):\n",
    "#         for col in range(ncol):\n",
    "\n",
    "#             # Devide normalized image into 32*32 regions\n",
    "#             region = enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32]\n",
    "\n",
    "#             # Perform histogram equalization for each 32*32 region\n",
    "#             enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32] = cv2.equalizeHist(region)\n",
    "\n",
    "#     return np.array(enhanced_normal)"
   ],
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sssff7joFllt"
   },
   "source": [
    "  "
   ],
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78poXfQ3e6Vk"
   },
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import math\n",
    "# import scipy\n",
    "# from scipy.spatial import distance\n",
    "# from scipy import signal\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # Define the modualting function as mentioned in Ma's paper\n",
    "# def M(x ,y, f):\n",
    "#     res = np.cos(2 * np.pi * f * math.sqrt(x ** 2 + y ** 2))\n",
    "#     return res\n",
    "\n",
    "# # Define the Spatial filter\n",
    "# def Gabor(x, y, dx, dy, f):\n",
    "#     # print(x, y, dx, dy, f)\n",
    "#     gabor = (1/(2 * np.pi * dx * dy)) * np.exp(-1/2 * (x ** 2/(dx ** 2) + y ** 2/(dy ** 2))) * M(x,y,f)\n",
    "#     return gabor\n",
    "\n",
    "\n",
    "# # Apply the defined filter to an 8 by 8 block \n",
    "# def block(dx, dy, f):\n",
    "#     feature = np.zeros((8,8))\n",
    "#     for i in range(8):\n",
    "#         for j in range(8):\n",
    "#             feature[i,j] = Gabor((-4+j),(-4+i),dx,dy,f)\n",
    "#     return feature\n",
    "\n",
    "\n",
    "# # The function inputs the two filtered image, calculates mean and std for each block of each channel, \n",
    "# # and returns the desired vector V with all means and stds appended to it.\n",
    "# def get_vector(vector1,vector2):\n",
    "#     feature_vec = []\n",
    "#     # ranges are determined by 48/8 = 6 and 512/8 = 64\n",
    "#     for i in range(6):\n",
    "#         for j in range(64):\n",
    "#             # Loop over each 8 by 8 block to get the feature\n",
    "#             x1 = 8 * i\n",
    "#             x2 = x1 + 8\n",
    "#             y1 = 8 * j\n",
    "#             y2 = y1 + 8\n",
    "            \n",
    "#             # Filtered image block\n",
    "#             c1 = vector1[x1:x2,y1:y2]\n",
    "#             c2 = vector2[x1:x2,y1:y2]\n",
    "            \n",
    "#             c1 = np.abs(c1)\n",
    "#             c2 = np.abs(c2)\n",
    "            \n",
    "#             # Follow the calculation steps in Ma's paper\n",
    "#             # Channel 1 mean and standard deviation\n",
    "#             m1 = np.mean(c1)\n",
    "#             sigma1 = np.mean(np.abs(c1-m1))\n",
    "#             feature_vec.append(m1)\n",
    "#             feature_vec.append(sigma1)\n",
    "            \n",
    "#             # Channel 2 mean and standard deviation\n",
    "#             m2 = np.mean(c2)\n",
    "#             sigma2 = np.mean(np.abs(c2-m2))\n",
    "#             feature_vec.append(m2)\n",
    "#             feature_vec.append(sigma2)\n",
    "            \n",
    "#     return feature_vec\n",
    "\n",
    "# # Inputs a single normalized image\n",
    "# def FeatureExtraction(enhanced_normal):\n",
    "#     f = 2/3\n",
    "#     # Get two channels using the parameters defined in paper\n",
    "#     channel1 = block(3, 1.5, f)\n",
    "#     channel2 = block(4, 1.5, f)\n",
    "    \n",
    "#     feature_vec = []\n",
    "    \n",
    "\n",
    "#     # enhanced_normal has length 64 and enhance_normal has length 512\n",
    "#     # Define a 48 by 512 region as ROI\n",
    "#     ROI = enhanced_normal[:48,:]\n",
    "\n",
    "#     filtered1 = scipy.signal.convolve2d(ROI,channel1,mode='same')\n",
    "#     filtered2 = scipy.signal.convolve2d(ROI,channel2,mode='same')\n",
    "    \n",
    "#     vector = get_vector(filtered1,filtered2)\n",
    "#     feature_vec.append(vector)\n",
    "#     # len(feature_vec) == 1536\n",
    "#     return np.array(feature_vec).flatten()"
   ],
   "execution_count": 169,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q5yWPiBAnNV4"
   },
   "source": [
    "# # def slice_per(source, step):\n",
    "# #     return [np.array(source[i::step]).reshape(-1,1536) for i in range(step)]\n",
    "\n",
    "# def LDA(df, target_dim):\n",
    "#   # data = np.array(data)\n",
    "#   mu = np.mean(df['feature'].values,axis=0).reshape(1536,1) # Mean vector mu --> Since the data has been standardized, the data means are zero \n",
    "#   mu_k = []\n",
    "\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       mu_k.append(np.mean(df[df['idx']==idx]['feature'],axis=0))\n",
    "#   mu_k = np.array(mu_k).T\n",
    "\n",
    "#   data_SW = []\n",
    "#   Nc = []\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       a = np.array(np.array(df[df['idx']==idx]['feature'].values.tolist()).reshape(-1, 1536)-mu_k[:,i].reshape(1,1536))\n",
    "#       data_SW.append(np.dot(a.T,a))\n",
    "#       Nc.append(np.sum(df['idx']==idx))\n",
    "#   SW = np.sum(data_SW,axis=0)\n",
    "\n",
    "#   SB = np.dot(Nc*np.array(mu_k-mu),np.array(mu_k-mu).T)\n",
    "#   eigval, eigvec = np.linalg.eig(np.dot(np.linalg.inv(SW),SB))\n",
    "\n",
    "#   eigen_pairs = [[np.abs(eigval[i]),eigvec[:,i]] for i in range(len(eigval))]\n",
    "#   eigen_pairs = sorted(eigen_pairs,key=lambda k: k[0],reverse=True)\n",
    "#   w = np.hstack([eigen_pairs[i][1][:,np.newaxis].real for i in range(target_dim)]) # Select two largest\n",
    "\n",
    "#   # 6. Transform the data with Y=X*w\n",
    "#   # Y = data.dot(w)\n",
    "\n",
    "#   return w\n",
    "\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5nDdQfI7qxzi"
   },
   "source": [
    "# images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "\n",
    "# boundary,center = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list = list(zip(boundary, center))\n",
    "\n",
    "# # M = 64\n",
    "# # N = 512\n",
    "# # rows = np.empty((N, M), dtype=object)\n",
    "# # for Y in range(M):\n",
    "# #     for X in range(N):\n",
    "# #         rows[X][Y] = (X, Y)\n",
    "\n"
   ],
   "execution_count": 170,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Wb6Z2MmeH7N"
   },
   "source": [
    "# normal_out = list(map(lambda x: normalization(x), bc_list))\n"
   ],
   "execution_count": 80,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OnLEZtlRjx6p"
   },
   "source": [
    "# res=list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), np.array(normal_out.copy())))\n",
    "# sliced_res = list(chunks(res,3))\n",
    "\n",
    "# list_of_dataframes = []\n",
    "# for i, eyes in enumerate(sliced_res):\n",
    "#   # i from 0 to 108\n",
    "#   for j, eye in enumerate(eyes):\n",
    "#     # j from 0 to 2\n",
    "#     degree = [-9,-6,-3,0,3,6,9]\n",
    "#     img_idx = [j]*7\n",
    "#     idx = [i]*7\n",
    "#     df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'data':eye})\n",
    "#     list_of_dataframes.append(df_tmp)\n",
    "# df = pd.concat(list_of_dataframes)\n"
   ],
   "execution_count": 111,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N1SPxUhNq5fd"
   },
   "source": [
    "# df['feature']=df['data'].apply(lambda x: FeatureExtraction(x))"
   ],
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VJ1Eunbyu3T-"
   },
   "source": [
    "# w = LDA(df, 40)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ev8Rm4ppAawG"
   },
   "source": [
    ""
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b3s7_OTbdcOm"
   },
   "source": [
    "# images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "# boundary_test,center_test = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list_test = list(zip(boundary_test, center_test))\n",
    "# normal_out_test = list(map(lambda x: normalization(x), bc_list_test))"
   ],
   "execution_count": 171,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YKlaJUTX1ztY"
   },
   "source": [
    "# sliced_res_test = list(chunks(normal_out_test, 4))\n",
    "\n",
    "# list_of_dataframes_test = []\n",
    "# for i, eyes in enumerate(sliced_res_test):\n",
    "# # i from 0 to 107\n",
    "#     for j, eye in enumerate(eyes):\n",
    "#         # j from 0 to 3\n",
    "#         img_idx = [j]\n",
    "#         idx = [i]\n",
    "#         df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'data':[eye]})\n",
    "#         list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "# df_test = pd.concat(list_of_dataframes_test)\n",
    "# df_test['feature']=df_test['data'].apply(lambda x: FeatureExtraction(x))\n"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aGnY83Synw-R"
   },
   "source": [
    "# clf = LinearDiscriminantAnalysis(n_components=40)\n",
    "# clf.fit(list(df['feature'].values), list(df['idx'].values))\n",
    "# df['new_feature']=df['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))\n",
    "# df_test['new_feature']=df_test['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))"
   ],
   "execution_count": 116,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6O3nqqIOhW_-"
   },
   "source": [
    "# df_test.head()"
   ],
   "execution_count": 172,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eZ461gpJ3-of"
   },
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('df_train.pkl', 'wb') as f:\n",
    "#   pickle.dump(df, f)\n",
    "\n",
    "# with open('df_test.pkl', 'wb') as f:\n",
    "#   pickle.dump(df_test, f)"
   ],
   "execution_count": 92,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WWt3a07J3-tU"
   },
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MYIf2SvP2HYO"
   },
   "source": [
    "def compute_dis(test_feature, target_feature, norm):\n",
    "  if norm == 1:\n",
    "    return np.sum(np.abs(test_feature-target_feature))\n",
    "  elif norm == 2:\n",
    "    return np.sum(np.square(test_feature-target_feature))\n",
    "  else:\n",
    "    return np.multiply(test_feature.T,target_feature)/(np.linalg.norm(test_feature)*np.linalg.norm(target_feature))"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l5sFfsYI4PrB"
   },
   "source": [
    "def get_class(df_train, test_feature, label, norm):\n",
    "  train_templates = df_train[label].values\n",
    "  # print(len(train_templates))\n",
    "  dis = list(map(lambda x: compute_dis(test_feature, x, norm),train_templates))\n",
    "  min_idx = np.argmin(dis)\n",
    "  # print(dis)\n",
    "  # print(min_idx)\n",
    "  return list(df_train['idx'].values)[min_idx]"
   ],
   "execution_count": 173,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e3Zpobb9GYz4"
   },
   "source": [
    "from IrisLocalization import IrisLocalization\n",
    "from IrisNormalization import IrisNormalization, getRotation\n",
    "from ImageEnhancement import ImageEnhancement\n",
    "from FeatureExtraction import FeatureExtraction\n",
    "from IrisMatching import IrisMatching\n",
    "from PerformanceEvaluation import PerformanceEvaluation"
   ],
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "temeoD3e98IN"
   },
   "source": [
    ""
   ],
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CbuOJnM78Qm",
    "outputId": "67c790c2-59f2-4549-962a-3a8b76eb0afe"
   },
   "source": [
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "rotate_train = sum(list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), normalized_train.copy())), [])\n",
    "enhanced_train=ImageEnhancement(rotate_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "\n",
    "'''TESTING'''\n",
    "\n",
    "#reading the testing images from the CASIA dataset\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")"
   ],
   "execution_count": 161,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data processed.\n",
      "Testing data processed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1BN9zSk-HGSy"
   },
   "source": [
    "sliced_res_train = list(chunks(feature_vector_train,21))\n",
    "\n",
    "list_of_dataframes_train = []\n",
    "for i, eyes in enumerate(sliced_res_train):\n",
    "# i from 0 to 107\n",
    "    sliced_eyes = list(chunks(eyes,7))\n",
    "    for j, eye in enumerate(sliced_eyes):\n",
    "        # j from 0 to 3\n",
    "        degree = [-9,-6,-3,0,3,6,9]\n",
    "        img_idx = [j]*7\n",
    "        idx = [i]*7\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'feature': eye })\n",
    "        list_of_dataframes_train.append(df_tmp)\n",
    "df_train = pd.concat(list_of_dataframes_train)"
   ],
   "execution_count": 162,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "cvTumK55HkMV",
    "outputId": "509056d4-e74d-423e-a2ad-ad0054e106dc"
   },
   "source": [
    "df_train.head(30)"
   ],
   "execution_count": 163,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>degree</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>[2.6575243038303014, 1.7622231652723543, 2.663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>[3.668468453938321, 2.4704599748816185, 3.3643...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>[5.395729228865787, 3.177060975406911, 4.61582...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.8484012907094205, 1.700563016754132, 2.7255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.879538355481692, 1.7155831474818104, 2.7895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.819595692663607, 1.7374680075559223, 2.7124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[2.717693250092032, 1.6578017169126733, 2.7199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>[2.869927555786551, 1.8650543880662749, 2.7504...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>[3.637516270432604, 2.265139522835423, 3.25552...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>[4.8701303305167185, 3.2790967884661293, 4.157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.864467306099926, 1.8859660882247802, 2.7671...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.8763656188989004, 1.878991016664728, 2.7139...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[3.0057904360559937, 1.8525578179829225, 2.765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[3.021318943478344, 2.036351804639553, 3.03920...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-9</td>\n",
       "      <td>[2.962515291872032, 1.6292833586322486, 2.7560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6</td>\n",
       "      <td>[3.6517141108858553, 2.27661544289802, 3.23204...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-3</td>\n",
       "      <td>[4.917588270982806, 3.185617323956781, 4.21716...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.7883329428297694, 1.7101965070730643, 2.733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.7022928608602017, 1.75796944758132, 2.75802...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.8752325651469137, 1.7184364845377353, 2.726...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>[2.867811937915632, 1.9914952863339672, 2.8908...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>[2.6238227346887126, 1.587753880155609, 2.5805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>[3.8246797667788, 2.404567224035733, 3.4046663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>[5.421010006454765, 3.019644211818148, 4.65881...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.458485899466581, 1.6333694229186717, 2.7577...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.554705634309961, 1.8189654456395319, 2.7290...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>[2.868083634765802, 1.9443550549192055, 2.9266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[2.8022496129181635, 2.0186498784197155, 2.765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-9</td>\n",
       "      <td>[2.570920449212879, 1.6940282018467363, 2.5505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-6</td>\n",
       "      <td>[3.7774510767304728, 2.4756909225167147, 3.365...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx  img_idx  degree                                            feature\n",
       "0    0        0      -9  [2.6575243038303014, 1.7622231652723543, 2.663...\n",
       "1    0        0      -6  [3.668468453938321, 2.4704599748816185, 3.3643...\n",
       "2    0        0      -3  [5.395729228865787, 3.177060975406911, 4.61582...\n",
       "3    0        0       0  [2.8484012907094205, 1.700563016754132, 2.7255...\n",
       "4    0        0       3  [2.879538355481692, 1.7155831474818104, 2.7895...\n",
       "5    0        0       6  [2.819595692663607, 1.7374680075559223, 2.7124...\n",
       "6    0        0       9  [2.717693250092032, 1.6578017169126733, 2.7199...\n",
       "0    0        1      -9  [2.869927555786551, 1.8650543880662749, 2.7504...\n",
       "1    0        1      -6  [3.637516270432604, 2.265139522835423, 3.25552...\n",
       "2    0        1      -3  [4.8701303305167185, 3.2790967884661293, 4.157...\n",
       "3    0        1       0  [2.864467306099926, 1.8859660882247802, 2.7671...\n",
       "4    0        1       3  [2.8763656188989004, 1.878991016664728, 2.7139...\n",
       "5    0        1       6  [3.0057904360559937, 1.8525578179829225, 2.765...\n",
       "6    0        1       9  [3.021318943478344, 2.036351804639553, 3.03920...\n",
       "0    0        2      -9  [2.962515291872032, 1.6292833586322486, 2.7560...\n",
       "1    0        2      -6  [3.6517141108858553, 2.27661544289802, 3.23204...\n",
       "2    0        2      -3  [4.917588270982806, 3.185617323956781, 4.21716...\n",
       "3    0        2       0  [2.7883329428297694, 1.7101965070730643, 2.733...\n",
       "4    0        2       3  [2.7022928608602017, 1.75796944758132, 2.75802...\n",
       "5    0        2       6  [2.8752325651469137, 1.7184364845377353, 2.726...\n",
       "6    0        2       9  [2.867811937915632, 1.9914952863339672, 2.8908...\n",
       "0    1        0      -9  [2.6238227346887126, 1.587753880155609, 2.5805...\n",
       "1    1        0      -6  [3.8246797667788, 2.404567224035733, 3.4046663...\n",
       "2    1        0      -3  [5.421010006454765, 3.019644211818148, 4.65881...\n",
       "3    1        0       0  [2.458485899466581, 1.6333694229186717, 2.7577...\n",
       "4    1        0       3  [2.554705634309961, 1.8189654456395319, 2.7290...\n",
       "5    1        0       6  [2.868083634765802, 1.9443550549192055, 2.9266...\n",
       "6    1        0       9  [2.8022496129181635, 2.0186498784197155, 2.765...\n",
       "0    1        1      -9  [2.570920449212879, 1.6940282018467363, 2.5505...\n",
       "1    1        1      -6  [3.7774510767304728, 2.4756909225167147, 3.365..."
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QhJi7oRHlQo"
   },
   "source": [
    "sliced_res_test = list(chunks(feature_vector_test,4))\n",
    "\n",
    "list_of_dataframes_test = []\n",
    "for i, eyes in enumerate(sliced_res_test):\n",
    "# i from 0 to 107\n",
    "    for j, eye in enumerate(eyes):\n",
    "        # j from 0 to 3\n",
    "        img_idx = [j]\n",
    "        idx = [i]\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'feature':[np.array(eye)]})\n",
    "        list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "df_test = pd.concat(list_of_dataframes_test)"
   ],
   "execution_count": 164,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQEVBnOccagi"
   },
   "source": [
    "df_test['class']=df_test['feature'].apply(lambda x: get_class(df_train.copy(), x, 'feature', 2))"
   ],
   "execution_count": 165,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "03QDfYnmc5wR",
    "outputId": "680c2ab5-aea7-438b-d7d4-0da76cfbdfdb"
   },
   "source": [
    "df_test"
   ],
   "execution_count": 166,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>img_idx</th>\n",
       "      <th>feature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.658850504628738, 1.7435804960876373, 2.5950...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[3.0357539912737086, 1.790094563450126, 2.8317...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[2.975477266381885, 1.767112510815004, 2.77444...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.7461316950609187, 1.5906885544690048, 2.781...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.733304351113559, 1.692351095465718, 2.64453...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.9248611774175073, 1.9044060105217093, 2.739...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.8611834517426056, 1.7109619725003462, 2.672...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "      <td>[2.5402519920851, 1.7155584051275297, 2.614675...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "      <td>[2.4176949869567244, 1.6375947859703657, 2.542...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>[2.800393951824835, 1.7117496971993909, 2.6308...</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx  img_idx                                            feature  class\n",
       "0     0        0  [2.658850504628738, 1.7435804960876373, 2.5950...     37\n",
       "0     0        1  [3.0357539912737086, 1.790094563450126, 2.8317...      0\n",
       "0     0        2  [2.975477266381885, 1.767112510815004, 2.77444...     58\n",
       "0     0        3  [2.7461316950609187, 1.5906885544690048, 2.781...     83\n",
       "0     1        0  [2.733304351113559, 1.692351095465718, 2.64453...      3\n",
       "..  ...      ...                                                ...    ...\n",
       "0   106        3  [2.9248611774175073, 1.9044060105217093, 2.739...    106\n",
       "0   107        0  [2.8611834517426056, 1.7109619725003462, 2.672...    107\n",
       "0   107        1  [2.5402519920851, 1.7155584051275297, 2.614675...    107\n",
       "0   107        2  [2.4176949869567244, 1.6375947859703657, 2.542...     18\n",
       "0   107        3  [2.800393951824835, 1.7117496971993909, 2.6308...    107\n",
       "\n",
       "[432 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 166
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WMPsJoh8c7gY"
   },
   "source": [
    "df_test['correct'] = df_test.apply(lambda x: int(x['idx']==x['class']), axis=1)"
   ],
   "execution_count": 167,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnxoUjiicmDd",
    "outputId": "77d0ffe3-9e33-491a-8363-6b399762a8ef"
   },
   "source": [
    "sum(df_test['correct'])"
   ],
   "execution_count": 168,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "metadata": {},
     "execution_count": 168
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JxE3SnBFJi20"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}