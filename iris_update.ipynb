{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "iris_update.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "XWnAg0aEd3C8"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jXfuyRInkyyj"
   },
   "source": [
    "#  !pip install unrar\n",
    "#  !unrar x CASIA.rar"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cUSDxdXEAt8G"
   },
   "source": [
    "# def IrisLocalization(images):\n",
    "#     # Convert all images to grayscale first\n",
    "#     images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "#     # Create empty lists to store boundary and center\n",
    "#     boundary = []\n",
    "#     center = []\n",
    "        \n",
    "    \n",
    "#     for img in images:\n",
    "#         # Blurring the image\n",
    "#         blurred = cv2.bilateralFilter(img,9,80,80)\n",
    "#         img = blurred\n",
    "\n",
    "\n",
    "#         # Estimating the center of the image\n",
    "#         horizontal_mean = np.mean(img,axis = 0)\n",
    "#         vertical_mean = np.mean(img,axis = 1)\n",
    "#         # The indices with the min values\n",
    "#         X_p = horizontal_mean.argmin()\n",
    "#         Y_p = vertical_mean.argmin()\n",
    "\n",
    "#         # Create a 120 * 120 region centered at the (X_p,Y_p)\n",
    "#         circle_x = img[X_p-60:X_p+60]\n",
    "#         circle_y = img[Y_p-60:Y_p+60]\n",
    "\n",
    "#         # Update the center and estimate center of the pupil\n",
    "#         horizontal_mean = np.mean(circle_y,axis = 0)\n",
    "#         vertical_mean = np.mean(circle_x,axis = 0)\n",
    "\n",
    "#         # Center of the 120*120 region\n",
    "#         xp = horizontal_mean.argmin()\n",
    "#         yp = vertical_mean.argmin()\n",
    "#         # Define center of the pupil\n",
    "#         pupil_center = (xp,yp)\n",
    "\n",
    "#         copy_img = img.copy()\n",
    "#         # Locate the pupil center and show it on the image with one point\n",
    "#         cv2.circle(copy_img,(xp,yp),1,(255,0,0),2)\n",
    "\n",
    "#         # Setting threshold\n",
    "#         masked_img = cv2.inRange(img,0,70)\n",
    "#         result = cv2.bitwise_and(img,masked_img)\n",
    "#         # Apply Canny detector on masked image\n",
    "#         img_edge = cv2.Canny(result, 100, 200)\n",
    "\n",
    "#         # Apply Hough transform to the edged image\n",
    "#         circle = cv2.HoughCircles(img_edge, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "\n",
    "#         min_dist = math.inf\n",
    "#         for i in range(len(circle[0])):\n",
    "\n",
    "#             c=(circle[0][i][0],circle[0][i][1])\n",
    "#             dist = distance.euclidean(pupil_center, c)\n",
    "#             if dist < min_dist:\n",
    "#                 min_dist = dist\n",
    "#                 k = circle[0][i]\n",
    "\n",
    "#         img_orig = img.copy()\n",
    "#         # Draw the inner boundary\n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), int(k[2]), (255, 0, 0), 2)\n",
    "\n",
    "#         pupil = k\n",
    "#         radius_pupil = int(k[2])\n",
    "\n",
    "#         # Draw the outer boundary, with the inner boundary adding about 55-60 depending on different people  \n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), radius_pupil+55, (255, 0, 0), 2)\n",
    "\n",
    "#         # plt.imshow(img_orig,cmap='gray')\n",
    "#         boundary.append(img_orig)\n",
    "#         center.append([int(k[0]),int(k[1]),int(k[2])])\n",
    "#     return boundary,center"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ToH4mp86erIL"
   },
   "source": [
    "# def normalization(data, target_array):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     def map_element(idx):\n",
    "#       X, Y = idx[0], idx[1]\n",
    "#       # print(idx)\n",
    "#       # print(X, Y)\n",
    "\n",
    "#       theta = 2 * np.pi * X/N\n",
    "#       # adjacent side for pupil and iris \n",
    "#       adj_p = np.cos(theta) * radius_pupil\n",
    "#       adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#       # opoosite side for pupil and iris\n",
    "#       oppo_p = np.sin(theta) * radius_pupil\n",
    "#       oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#       # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#       x_p = int(np.round(x_pupil + adj_p))\n",
    "#       y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#       # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#       x_i = int(np.round(x_pupil + adj_i))\n",
    "#       y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#       # x & y (new projection) from equation\n",
    "#       x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#       y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#       # x & y should not exceed image boundary i.e(320,280)\n",
    "#       if y >= 320:\n",
    "#           y = 319\n",
    "#       if x >= 280:\n",
    "#           x = 279\n",
    "#       return img[x, y]\n",
    "\n",
    "\n",
    "#     # print(rows.shape)\n",
    "#     myfunc_vec = np.vectorize(map_element)\n",
    "#     normalized = myfunc_vec(target_array)\n",
    "#     return normalized\n",
    "#     #return normalized"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sevoDNwKxTyo"
   },
   "source": [
    "# def normalization(data):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     normalized = []\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     M = 64\n",
    "#     N = 512\n",
    "\n",
    "#     for Y in range(M):\n",
    "#         row_pix = []\n",
    "        \n",
    "#         for X in range(N):\n",
    "#             theta = 2 * np.pi * X/N\n",
    "#             # adjacent side for pupil and iris \n",
    "#             adj_p = np.cos(theta) * radius_pupil\n",
    "#             adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#             # opoosite side for pupil and iris\n",
    "#             oppo_p = np.sin(theta) * radius_pupil\n",
    "#             oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#             # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#             x_p = int(np.round(x_pupil + adj_p))\n",
    "#             y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#             # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#             x_i = int(np.round(x_pupil + adj_i))\n",
    "#             y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#             # x & y (new projection) from equation\n",
    "#             x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#             y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#             # x & y should not exceed image boundary i.e(320,280)\n",
    "#             if y >= 320:\n",
    "#                 y = 319\n",
    "#             if x >= 280:\n",
    "#                 x = 279\n",
    "    \n",
    "#             row_pix.append(img[x, y])\n",
    "#         normalized.append(np.array(row_pix))\n",
    "\n",
    "#     return ImageEnhancement(np.array(normalized))\n",
    "#     #return normalized"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PeeHHQYAFi-7"
   },
   "source": [
    "# def ImageEnhancement(normalized):\n",
    " \n",
    "#     enhanced_normal = normalized.copy()\n",
    "\n",
    "#     # range for row and column\n",
    "#     nrow = int(normalized.shape[0]/32) # 2\n",
    "#     ncol = int(normalized.shape[1]/32) # 16\n",
    "\n",
    "#     # The following loop will first define each 32*32 region in normalized image\n",
    "#     # and then perform histogram equalization in each divided region\n",
    "    \n",
    "#     for row in range(nrow):\n",
    "#         for col in range(ncol):\n",
    "\n",
    "#             # Devide normalized image into 32*32 regions\n",
    "#             region = enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32]\n",
    "\n",
    "#             # Perform histogram equalization for each 32*32 region\n",
    "#             enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32] = cv2.equalizeHist(region)\n",
    "\n",
    "#     return np.array(enhanced_normal)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sssff7joFllt"
   },
   "source": [
    "  "
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78poXfQ3e6Vk"
   },
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import math\n",
    "# import scipy\n",
    "# from scipy.spatial import distance\n",
    "# from scipy import signal\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # Define the modualting function as mentioned in Ma's paper\n",
    "# def M(x ,y, f):\n",
    "#     res = np.cos(2 * np.pi * f * math.sqrt(x ** 2 + y ** 2))\n",
    "#     return res\n",
    "\n",
    "# # Define the Spatial filter\n",
    "# def Gabor(x, y, dx, dy, f):\n",
    "#     # print(x, y, dx, dy, f)\n",
    "#     gabor = (1/(2 * np.pi * dx * dy)) * np.exp(-1/2 * (x ** 2/(dx ** 2) + y ** 2/(dy ** 2))) * M(x,y,f)\n",
    "#     return gabor\n",
    "\n",
    "\n",
    "# # Apply the defined filter to an 8 by 8 block \n",
    "# def block(dx, dy, f):\n",
    "#     feature = np.zeros((8,8))\n",
    "#     for i in range(8):\n",
    "#         for j in range(8):\n",
    "#             feature[i,j] = Gabor((-4+j),(-4+i),dx,dy,f)\n",
    "#     return feature\n",
    "\n",
    "\n",
    "# # The function inputs the two filtered image, calculates mean and std for each block of each channel, \n",
    "# # and returns the desired vector V with all means and stds appended to it.\n",
    "# def get_vector(vector1,vector2):\n",
    "#     feature_vec = []\n",
    "#     # ranges are determined by 48/8 = 6 and 512/8 = 64\n",
    "#     for i in range(6):\n",
    "#         for j in range(64):\n",
    "#             # Loop over each 8 by 8 block to get the feature\n",
    "#             x1 = 8 * i\n",
    "#             x2 = x1 + 8\n",
    "#             y1 = 8 * j\n",
    "#             y2 = y1 + 8\n",
    "            \n",
    "#             # Filtered image block\n",
    "#             c1 = vector1[x1:x2,y1:y2]\n",
    "#             c2 = vector2[x1:x2,y1:y2]\n",
    "            \n",
    "#             c1 = np.abs(c1)\n",
    "#             c2 = np.abs(c2)\n",
    "            \n",
    "#             # Follow the calculation steps in Ma's paper\n",
    "#             # Channel 1 mean and standard deviation\n",
    "#             m1 = np.mean(c1)\n",
    "#             sigma1 = np.mean(np.abs(c1-m1))\n",
    "#             feature_vec.append(m1)\n",
    "#             feature_vec.append(sigma1)\n",
    "            \n",
    "#             # Channel 2 mean and standard deviation\n",
    "#             m2 = np.mean(c2)\n",
    "#             sigma2 = np.mean(np.abs(c2-m2))\n",
    "#             feature_vec.append(m2)\n",
    "#             feature_vec.append(sigma2)\n",
    "            \n",
    "#     return feature_vec\n",
    "\n",
    "# # Inputs a single normalized image\n",
    "# def FeatureExtraction(enhanced_normal):\n",
    "#     f = 2/3\n",
    "#     # Get two channels using the parameters defined in paper\n",
    "#     channel1 = block(3, 1.5, f)\n",
    "#     channel2 = block(4, 1.5, f)\n",
    "    \n",
    "#     feature_vec = []\n",
    "    \n",
    "\n",
    "#     # enhanced_normal has length 64 and enhance_normal has length 512\n",
    "#     # Define a 48 by 512 region as ROI\n",
    "#     ROI = enhanced_normal[:48,:]\n",
    "\n",
    "#     filtered1 = scipy.signal.convolve2d(ROI,channel1,mode='same')\n",
    "#     filtered2 = scipy.signal.convolve2d(ROI,channel2,mode='same')\n",
    "    \n",
    "#     vector = get_vector(filtered1,filtered2)\n",
    "#     feature_vec.append(vector)\n",
    "#     # len(feature_vec) == 1536\n",
    "#     return np.array(feature_vec).flatten()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q5yWPiBAnNV4"
   },
   "source": [
    "# # def slice_per(source, step):\n",
    "# #     return [np.array(source[i::step]).reshape(-1,1536) for i in range(step)]\n",
    "\n",
    "# def LDA(df, target_dim):\n",
    "#   # data = np.array(data)\n",
    "#   mu = np.mean(df['feature'].values,axis=0).reshape(1536,1) # Mean vector mu --> Since the data has been standardized, the data means are zero \n",
    "#   mu_k = []\n",
    "\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       mu_k.append(np.mean(df[df['idx']==idx]['feature'],axis=0))\n",
    "#   mu_k = np.array(mu_k).T\n",
    "\n",
    "#   data_SW = []\n",
    "#   Nc = []\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       a = np.array(np.array(df[df['idx']==idx]['feature'].values.tolist()).reshape(-1, 1536)-mu_k[:,i].reshape(1,1536))\n",
    "#       data_SW.append(np.dot(a.T,a))\n",
    "#       Nc.append(np.sum(df['idx']==idx))\n",
    "#   SW = np.sum(data_SW,axis=0)\n",
    "\n",
    "#   SB = np.dot(Nc*np.array(mu_k-mu),np.array(mu_k-mu).T)\n",
    "#   eigval, eigvec = np.linalg.eig(np.dot(np.linalg.inv(SW),SB))\n",
    "\n",
    "#   eigen_pairs = [[np.abs(eigval[i]),eigvec[:,i]] for i in range(len(eigval))]\n",
    "#   eigen_pairs = sorted(eigen_pairs,key=lambda k: k[0],reverse=True)\n",
    "#   w = np.hstack([eigen_pairs[i][1][:,np.newaxis].real for i in range(target_dim)]) # Select two largest\n",
    "\n",
    "#   # 6. Transform the data with Y=X*w\n",
    "#   # Y = data.dot(w)\n",
    "\n",
    "#   return w\n",
    "\n"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5nDdQfI7qxzi"
   },
   "source": [
    "# images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "\n",
    "# boundary,center = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list = list(zip(boundary, center))\n",
    "\n",
    "# # M = 64\n",
    "# # N = 512\n",
    "# # rows = np.empty((N, M), dtype=object)\n",
    "# # for Y in range(M):\n",
    "# #     for X in range(N):\n",
    "# #         rows[X][Y] = (X, Y)\n",
    "\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Wb6Z2MmeH7N"
   },
   "source": [
    "# normal_out = list(map(lambda x: normalization(x), bc_list))\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OnLEZtlRjx6p"
   },
   "source": [
    "# res=list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), np.array(normal_out.copy())))\n",
    "# sliced_res = list(chunks(res,3))\n",
    "\n",
    "# list_of_dataframes = []\n",
    "# for i, eyes in enumerate(sliced_res):\n",
    "#   # i from 0 to 108\n",
    "#   for j, eye in enumerate(eyes):\n",
    "#     # j from 0 to 2\n",
    "#     degree = [-9,-6,-3,0,3,6,9]\n",
    "#     img_idx = [j]*7\n",
    "#     idx = [i]*7\n",
    "#     df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'data':eye})\n",
    "#     list_of_dataframes.append(df_tmp)\n",
    "# df = pd.concat(list_of_dataframes)\n"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N1SPxUhNq5fd"
   },
   "source": [
    "# df['feature']=df['data'].apply(lambda x: FeatureExtraction(x))"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VJ1Eunbyu3T-"
   },
   "source": [
    "# w = LDA(df, 40)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ev8Rm4ppAawG"
   },
   "source": [],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b3s7_OTbdcOm"
   },
   "source": [
    "# images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "# boundary_test,center_test = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list_test = list(zip(boundary_test, center_test))\n",
    "# normal_out_test = list(map(lambda x: normalization(x), bc_list_test))"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YKlaJUTX1ztY"
   },
   "source": [
    "# sliced_res_test = list(chunks(normal_out_test, 4))\n",
    "\n",
    "# list_of_dataframes_test = []\n",
    "# for i, eyes in enumerate(sliced_res_test):\n",
    "# # i from 0 to 107\n",
    "#     for j, eye in enumerate(eyes):\n",
    "#         # j from 0 to 3\n",
    "#         img_idx = [j]\n",
    "#         idx = [i]\n",
    "#         df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'data':[eye]})\n",
    "#         list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "# df_test = pd.concat(list_of_dataframes_test)\n",
    "# df_test['feature']=df_test['data'].apply(lambda x: FeatureExtraction(x))\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aGnY83Synw-R"
   },
   "source": [
    "# clf = LinearDiscriminantAnalysis(n_components=40)\n",
    "# clf.fit(list(df['feature'].values), list(df['idx'].values))\n",
    "# df['new_feature']=df['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))\n",
    "# df_test['new_feature']=df_test['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6O3nqqIOhW_-"
   },
   "source": [
    "# df_test.head()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eZ461gpJ3-of"
   },
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('df_train.pkl', 'wb') as f:\n",
    "#   pickle.dump(df, f)\n",
    "\n",
    "# with open('df_test.pkl', 'wb') as f:\n",
    "#   pickle.dump(df_test, f)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WWt3a07J3-tU"
   },
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MYIf2SvP2HYO"
   },
   "source": [
    "def compute_dis(test_feature, target_feature, norm):\n",
    "  if norm == 1:\n",
    "    return np.sum(np.abs(test_feature-target_feature))\n",
    "  elif norm == 2:\n",
    "    return np.sum(np.square(test_feature-target_feature))\n",
    "  else:\n",
    "    return 1-np.dot(test_feature,target_feature.T)/(np.linalg.norm(test_feature)*np.linalg.norm(target_feature))"
   ],
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l5sFfsYI4PrB"
   },
   "source": [
    "def get_class(df_train, test_feature, label, norm):\n",
    "  train_templates = df_train[label].values\n",
    "  # print(len(train_templates))\n",
    "  dis = list(map(lambda x: compute_dis(test_feature, x, norm),train_templates))\n",
    "  min_idx = np.argmin(dis)\n",
    "  # print(dis)\n",
    "  # print(min_idx)\n",
    "  return list(df_train['idx'].values)[min_idx]"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e3Zpobb9GYz4"
   },
   "source": [
    "from IrisLocalization import IrisLocalization\n",
    "from IrisNormalization import IrisNormalization, getRotation\n",
    "from ImageEnhancement import ImageEnhancement\n",
    "from FeatureExtraction import FeatureExtraction\n",
    "# from IrisMatching import IrisMatching\n",
    "# from PerformanceEvaluation import PerformanceEvaluation"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "temeoD3e98IN"
   },
   "source": [],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CbuOJnM78Qm",
    "outputId": "67c790c2-59f2-4549-962a-3a8b76eb0afe"
   },
   "source": [],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/fred/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data processed.\n",
      "Testing data processed.\n"
     ]
    }
   ],
   "source": [
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "rotate_train = sum(list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), normalized_train.copy())), [])\n",
    "\n",
    "enhanced_train=ImageEnhancement(rotate_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "\n",
    "'''TESTING'''\n",
    "\n",
    "#reading the testing images from the CASIA dataset\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1BN9zSk-HGSy"
   },
   "source": [
    "sliced_res_train = list(chunks(feature_vector_train,21))\n",
    "\n",
    "list_of_dataframes_train = []\n",
    "for i, eyes in enumerate(sliced_res_train):\n",
    "# i from 0 to 107\n",
    "    sliced_eyes = list(chunks(eyes,7))\n",
    "    for j, eye in enumerate(sliced_eyes):\n",
    "        # j from 0 to 3\n",
    "        degree = [-9,-6,-3,0,3,6,9]\n",
    "        img_idx = [j]*7\n",
    "        idx = [i]*7\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'feature': eye })\n",
    "        list_of_dataframes_train.append(df_tmp)\n",
    "df_train = pd.concat(list_of_dataframes_train)"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "cvTumK55HkMV",
    "outputId": "509056d4-e74d-423e-a2ad-ad0054e106dc"
   },
   "source": [
    "df_train.head(30)"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "   idx  img_idx  degree                                            feature\n0    0        0      -9  [2.638736638194711, 1.3574609203917083, 2.4627...\n1    0        0      -6  [3.1273426140515808, 1.8551483585417126, 2.713...\n2    0        0      -3  [4.296016571451879, 2.7646819545577115, 3.5825...\n3    0        0       0  [2.6555895432097385, 1.587089572801086, 2.4394...\n4    0        0       3  [2.643265412274907, 1.353220768436026, 2.47770...\n5    0        0       6  [2.6797166130327477, 1.3894639159199502, 2.469...\n6    0        0       9  [2.6999285077568946, 1.7525993648945142, 2.420...\n0    0        1      -9  [2.6432563173973023, 1.3806721881412476, 2.468...\n1    0        1      -6  [3.0534484410553757, 1.8289811368398294, 2.654...\n2    0        1      -3  [4.117139412504908, 2.7848707921308296, 3.4449...\n3    0        1       0  [2.7131120437895806, 1.6099683370401312, 2.481...\n4    0        1       3  [2.6276273680897146, 1.4083904439725727, 2.447...\n5    0        1       6  [2.686050630073314, 1.3952324905821216, 2.4715...\n6    0        1       9  [2.8379980897928947, 2.0717863266192156, 2.585...\n0    0        2      -9  [2.6277521786540703, 1.363643638381309, 2.4434...\n1    0        2      -6  [3.1401915496450945, 1.8426800981396938, 2.723...\n2    0        2      -3  [4.16735194658864, 2.8237125386426776, 3.48393...\n3    0        2       0  [2.6585137053097787, 1.5441328534595515, 2.447...\n4    0        2       3  [2.6174978229475863, 1.4510670080669223, 2.446...\n5    0        2       6  [2.729737671178027, 1.4402941196281518, 2.4986...\n6    0        2       9  [2.9169472933970955, 2.1116778329572146, 2.648...\n0    1        0      -9  [2.502725825805447, 1.531919359471909, 2.32190...\n1    1        0      -6  [3.337335325377694, 1.828934338787452, 2.87431...\n2    1        0      -3  [4.257020935575042, 3.127667338959114, 3.63810...\n3    1        0       0  [2.6910332973527438, 1.6344559388858981, 2.549...\n4    1        0       3  [2.4588391633404796, 1.2996731551630898, 2.347...\n5    1        0       6  [2.943909463529417, 1.8789556507693164, 2.7346...\n6    1        0       9  [2.8321530129063133, 1.8872201868411191, 2.528...\n0    1        1      -9  [2.6380820378944385, 1.326587129263046, 2.4741...\n1    1        1      -6  [3.3248495133275946, 1.8204110961390783, 2.865...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>img_idx</th>\n      <th>degree</th>\n      <th>feature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>[2.638736638194711, 1.3574609203917083, 2.4627...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-6</td>\n      <td>[3.1273426140515808, 1.8551483585417126, 2.713...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>-3</td>\n      <td>[4.296016571451879, 2.7646819545577115, 3.5825...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[2.6555895432097385, 1.587089572801086, 2.4394...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>[2.643265412274907, 1.353220768436026, 2.47770...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>6</td>\n      <td>[2.6797166130327477, 1.3894639159199502, 2.469...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>0</td>\n      <td>9</td>\n      <td>[2.6999285077568946, 1.7525993648945142, 2.420...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-9</td>\n      <td>[2.6432563173973023, 1.3806721881412476, 2.468...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-6</td>\n      <td>[3.0534484410553757, 1.8289811368398294, 2.654...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>[4.117139412504908, 2.7848707921308296, 3.4449...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[2.7131120437895806, 1.6099683370401312, 2.481...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>[2.6276273680897146, 1.4083904439725727, 2.447...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>[2.686050630073314, 1.3952324905821216, 2.4715...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>1</td>\n      <td>9</td>\n      <td>[2.8379980897928947, 2.0717863266192156, 2.585...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>-9</td>\n      <td>[2.6277521786540703, 1.363643638381309, 2.4434...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>-6</td>\n      <td>[3.1401915496450945, 1.8426800981396938, 2.723...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>-3</td>\n      <td>[4.16735194658864, 2.8237125386426776, 3.48393...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>[2.6585137053097787, 1.5441328534595515, 2.447...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>[2.6174978229475863, 1.4510670080669223, 2.446...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>[2.729737671178027, 1.4402941196281518, 2.4986...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>2</td>\n      <td>9</td>\n      <td>[2.9169472933970955, 2.1116778329572146, 2.648...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-9</td>\n      <td>[2.502725825805447, 1.531919359471909, 2.32190...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-6</td>\n      <td>[3.337335325377694, 1.828934338787452, 2.87431...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>-3</td>\n      <td>[4.257020935575042, 3.127667338959114, 3.63810...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[2.6910332973527438, 1.6344559388858981, 2.549...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>[2.4588391633404796, 1.2996731551630898, 2.347...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>[2.943909463529417, 1.8789556507693164, 2.7346...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>0</td>\n      <td>9</td>\n      <td>[2.8321530129063133, 1.8872201868411191, 2.528...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-9</td>\n      <td>[2.6380820378944385, 1.326587129263046, 2.4741...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>-6</td>\n      <td>[3.3248495133275946, 1.8204110961390783, 2.865...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QhJi7oRHlQo"
   },
   "source": [
    "sliced_res_test = list(chunks(feature_vector_test,4))\n",
    "\n",
    "list_of_dataframes_test = []\n",
    "for i, eyes in enumerate(sliced_res_test):\n",
    "# i from 0 to 107\n",
    "    for j, eye in enumerate(eyes):\n",
    "        # j from 0 to 3\n",
    "        img_idx = [j]\n",
    "        idx = [i]\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'feature':[np.array(eye)]})\n",
    "        list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "df_test = pd.concat(list_of_dataframes_test)"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "clf = LDA(n_components=100)\n",
    "clf.fit(list(df_train['feature'].values), list(df_train['idx'].values))\n",
    "df_train['reduced_feature']=df_train['feature'].apply(lambda x: clf.transform(np.array(x).reshape(1, -1)))\n",
    "df_test['reduced_feature']=df_test['feature'].apply(lambda x: clf.transform(np.array(x).reshape(1, -1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQEVBnOccagi"
   },
   "source": [
    "df_test['class']=df_test['reduced_feature'].apply(lambda x: get_class(df_train.copy(), x, 'reduced_feature', 3))"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "03QDfYnmc5wR",
    "outputId": "680c2ab5-aea7-438b-d7d4-0da76cfbdfdb"
   },
   "source": [
    "df_test.head()"
   ],
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "   idx  img_idx                                            feature  \\\n0    0        0  [2.6960198767040793, 1.6083355844469476, 2.465...   \n0    0        1  [2.48225957142089, 1.3850534658622398, 2.28055...   \n0    0        2  [2.4794264028885826, 1.363258553595395, 2.2680...   \n0    0        3  [2.689122130985811, 1.5979620594180854, 2.4689...   \n0    1        0  [2.7061836293109636, 1.6074858953362152, 2.472...   \n\n                                     reduced_feature  class  correct  \n0  [[7.849147714412596, -1.5278716173992475, 7.03...      0        0  \n0  [[-0.652378603183107, -11.713657942189279, -15...      0        0  \n0  [[-4.3093914678819845, -11.365256375740028, -1...      0        0  \n0  [[-11.329929535493841, 10.64272343649355, -3.5...      0        0  \n0  [[12.229389357633039, 11.48115861411882, 1.643...      1        0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idx</th>\n      <th>img_idx</th>\n      <th>feature</th>\n      <th>reduced_feature</th>\n      <th>class</th>\n      <th>correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>[2.6960198767040793, 1.6083355844469476, 2.465...</td>\n      <td>[[7.849147714412596, -1.5278716173992475, 7.03...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>[2.48225957142089, 1.3850534658622398, 2.28055...</td>\n      <td>[[-0.652378603183107, -11.713657942189279, -15...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2</td>\n      <td>[2.4794264028885826, 1.363258553595395, 2.2680...</td>\n      <td>[[-4.3093914678819845, -11.365256375740028, -1...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>[2.689122130985811, 1.5979620594180854, 2.4689...</td>\n      <td>[[-11.329929535493841, 10.64272343649355, -3.5...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>[2.7061836293109636, 1.6074858953362152, 2.472...</td>\n      <td>[[12.229389357633039, 11.48115861411882, 1.643...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WMPsJoh8c7gY"
   },
   "source": [
    "df_test['correct'] = df_test.apply(lambda x: int(x['idx']==x['class']), axis=1)"
   ],
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnxoUjiicmDd",
    "outputId": "77d0ffe3-9e33-491a-8363-6b399762a8ef"
   },
   "source": [
    "sum(df_test['correct'])"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "317"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JxE3SnBFJi20"
   },
   "source": [
    "fi = df_train['reduced_feature'].values[0]\n",
    "f = df_test['reduced_feature'].values[0]"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-5.80669738e-03,  1.13029955e-03, -5.20551934e-03, ...,\n         2.03198929e-03, -6.72130278e-03,  1.32720480e-04],\n       [ 1.27661788e-03, -2.48499366e-04,  1.14444729e-03, ...,\n        -4.46738256e-04,  1.47769631e-03, -2.91789510e-05],\n       [-1.51429663e-02,  2.94764595e-03, -1.35751872e-02, ...,\n         5.29911297e-03, -1.75281154e-02,  3.46114431e-04],\n       ...,\n       [-4.43716932e-03,  8.63714802e-04, -3.97778103e-03, ...,\n         1.55273815e-03, -5.13606212e-03,  1.01417932e-04],\n       [-1.73535278e-03,  3.37794160e-04, -1.55568852e-03, ...,\n         6.07267441e-04, -2.00868595e-03,  3.96640016e-05],\n       [ 1.24914468e-03, -2.43151585e-04,  1.11981844e-03, ...,\n        -4.37124315e-04,  1.44589585e-03, -2.85510112e-05]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_dis(fi, f, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1232.59465609]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.dot(f,fi.T)/(np.linalg.norm(test_feature)*np.linalg.norm(target_feature))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}