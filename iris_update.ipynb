{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "iris_update.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "XWnAg0aEd3C8"
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import math\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jXfuyRInkyyj"
   },
   "source": [
    "#  !pip install unrar\n",
    "#  !unrar x CASIA.rar"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cUSDxdXEAt8G"
   },
   "source": [
    "# def IrisLocalization(images):\n",
    "#     # Convert all images to grayscale first\n",
    "#     images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "#     # Create empty lists to store boundary and center\n",
    "#     boundary = []\n",
    "#     center = []\n",
    "        \n",
    "    \n",
    "#     for img in images:\n",
    "#         # Blurring the image\n",
    "#         blurred = cv2.bilateralFilter(img,9,80,80)\n",
    "#         img = blurred\n",
    "\n",
    "\n",
    "#         # Estimating the center of the image\n",
    "#         horizontal_mean = np.mean(img,axis = 0)\n",
    "#         vertical_mean = np.mean(img,axis = 1)\n",
    "#         # The indices with the min values\n",
    "#         X_p = horizontal_mean.argmin()\n",
    "#         Y_p = vertical_mean.argmin()\n",
    "\n",
    "#         # Create a 120 * 120 region centered at the (X_p,Y_p)\n",
    "#         circle_x = img[X_p-60:X_p+60]\n",
    "#         circle_y = img[Y_p-60:Y_p+60]\n",
    "\n",
    "#         # Update the center and estimate center of the pupil\n",
    "#         horizontal_mean = np.mean(circle_y,axis = 0)\n",
    "#         vertical_mean = np.mean(circle_x,axis = 0)\n",
    "\n",
    "#         # Center of the 120*120 region\n",
    "#         xp = horizontal_mean.argmin()\n",
    "#         yp = vertical_mean.argmin()\n",
    "#         # Define center of the pupil\n",
    "#         pupil_center = (xp,yp)\n",
    "\n",
    "#         copy_img = img.copy()\n",
    "#         # Locate the pupil center and show it on the image with one point\n",
    "#         cv2.circle(copy_img,(xp,yp),1,(255,0,0),2)\n",
    "\n",
    "#         # Setting threshold\n",
    "#         masked_img = cv2.inRange(img,0,70)\n",
    "#         result = cv2.bitwise_and(img,masked_img)\n",
    "#         # Apply Canny detector on masked image\n",
    "#         img_edge = cv2.Canny(result, 100, 200)\n",
    "\n",
    "#         # Apply Hough transform to the edged image\n",
    "#         circle = cv2.HoughCircles(img_edge, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "\n",
    "#         min_dist = math.inf\n",
    "#         for i in range(len(circle[0])):\n",
    "\n",
    "#             c=(circle[0][i][0],circle[0][i][1])\n",
    "#             dist = distance.euclidean(pupil_center, c)\n",
    "#             if dist < min_dist:\n",
    "#                 min_dist = dist\n",
    "#                 k = circle[0][i]\n",
    "\n",
    "#         img_orig = img.copy()\n",
    "#         # Draw the inner boundary\n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), int(k[2]), (255, 0, 0), 2)\n",
    "\n",
    "#         pupil = k\n",
    "#         radius_pupil = int(k[2])\n",
    "\n",
    "#         # Draw the outer boundary, with the inner boundary adding about 55-60 depending on different people  \n",
    "#         cv2.circle(img_orig, (int(k[0]), int(k[1])), radius_pupil+55, (255, 0, 0), 2)\n",
    "\n",
    "#         # plt.imshow(img_orig,cmap='gray')\n",
    "#         boundary.append(img_orig)\n",
    "#         center.append([int(k[0]),int(k[1]),int(k[2])])\n",
    "#     return boundary,center"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ToH4mp86erIL"
   },
   "source": [
    "# def normalization(data, target_array):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     def map_element(idx):\n",
    "#       X, Y = idx[0], idx[1]\n",
    "#       # print(idx)\n",
    "#       # print(X, Y)\n",
    "\n",
    "#       theta = 2 * np.pi * X/N\n",
    "#       # adjacent side for pupil and iris \n",
    "#       adj_p = np.cos(theta) * radius_pupil\n",
    "#       adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#       # opoosite side for pupil and iris\n",
    "#       oppo_p = np.sin(theta) * radius_pupil\n",
    "#       oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#       # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#       x_p = int(np.round(x_pupil + adj_p))\n",
    "#       y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#       # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#       x_i = int(np.round(x_pupil + adj_i))\n",
    "#       y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#       # x & y (new projection) from equation\n",
    "#       x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#       y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#       # x & y should not exceed image boundary i.e(320,280)\n",
    "#       if y >= 320:\n",
    "#           y = 319\n",
    "#       if x >= 280:\n",
    "#           x = 279\n",
    "#       return img[x, y]\n",
    "\n",
    "\n",
    "#     # print(rows.shape)\n",
    "#     myfunc_vec = np.vectorize(map_element)\n",
    "#     normalized = myfunc_vec(target_array)\n",
    "#     return normalized\n",
    "#     #return normalized"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sevoDNwKxTyo"
   },
   "source": [
    "# def normalization(data):\n",
    "#     img, centers = data[0], data[1]\n",
    "#     # print(len(img), len(img[0]))\n",
    "#     # for img in target:\n",
    "#     #load pupil centers and radius of inner circles\n",
    "#     x_pupil = centers[0]\n",
    "#     y_pupil = centers[1]\n",
    "#     radius_pupil = int(centers[2])\n",
    "#     normalized = []\n",
    "#     radius_iris = 55 # width of space between inner and outer boundary\n",
    "\n",
    "#     M = 64\n",
    "#     N = 512\n",
    "\n",
    "#     for Y in range(M):\n",
    "#         row_pix = []\n",
    "        \n",
    "#         for X in range(N):\n",
    "#             theta = 2 * np.pi * X/N\n",
    "#             # adjacent side for pupil and iris \n",
    "#             adj_p = np.cos(theta) * radius_pupil\n",
    "#             adj_i = np.cos(theta) * radius_iris\n",
    "\n",
    "#             # opoosite side for pupil and iris\n",
    "#             oppo_p = np.sin(theta) * radius_pupil\n",
    "#             oppo_i = np.sin(theta) * radius_iris\n",
    "\n",
    "#             # points on pupil circle: x_p(theta) and y_p(theta) from equation\n",
    "#             x_p = int(np.round(x_pupil + adj_p))\n",
    "#             y_p = int(np.round(y_pupil + oppo_p))\n",
    "\n",
    "#             # points on iris circile: x_i(theta) and y_i(theta) from equation \n",
    "#             x_i = int(np.round(x_pupil + adj_i))\n",
    "#             y_i = int(np.round(y_pupil + oppo_i))\n",
    "\n",
    "#             # x & y (new projection) from equation\n",
    "#             x = int(x_p + (x_i - x_p) * (Y/M))\n",
    "#             y = int(y_p + (y_i - y_p) * (Y/M))\n",
    "\n",
    "#             # x & y should not exceed image boundary i.e(320,280)\n",
    "#             if y >= 320:\n",
    "#                 y = 319\n",
    "#             if x >= 280:\n",
    "#                 x = 279\n",
    "    \n",
    "#             row_pix.append(img[x, y])\n",
    "#         normalized.append(np.array(row_pix))\n",
    "\n",
    "#     return ImageEnhancement(np.array(normalized))\n",
    "#     #return normalized"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PeeHHQYAFi-7"
   },
   "source": [
    "# def ImageEnhancement(normalized):\n",
    " \n",
    "#     enhanced_normal = normalized.copy()\n",
    "\n",
    "#     # range for row and column\n",
    "#     nrow = int(normalized.shape[0]/32) # 2\n",
    "#     ncol = int(normalized.shape[1]/32) # 16\n",
    "\n",
    "#     # The following loop will first define each 32*32 region in normalized image\n",
    "#     # and then perform histogram equalization in each divided region\n",
    "    \n",
    "#     for row in range(nrow):\n",
    "#         for col in range(ncol):\n",
    "\n",
    "#             # Devide normalized image into 32*32 regions\n",
    "#             region = enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32]\n",
    "\n",
    "#             # Perform histogram equalization for each 32*32 region\n",
    "#             enhanced_normal[row*32 : (row+1)*32, col*32 : (col+1)*32] = cv2.equalizeHist(region)\n",
    "\n",
    "#     return np.array(enhanced_normal)"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sssff7joFllt"
   },
   "source": [
    "  "
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "78poXfQ3e6Vk"
   },
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import math\n",
    "# import scipy\n",
    "# from scipy.spatial import distance\n",
    "# from scipy import signal\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # Define the modualting function as mentioned in Ma's paper\n",
    "# def M(x ,y, f):\n",
    "#     res = np.cos(2 * np.pi * f * math.sqrt(x ** 2 + y ** 2))\n",
    "#     return res\n",
    "\n",
    "# # Define the Spatial filter\n",
    "# def Gabor(x, y, dx, dy, f):\n",
    "#     # print(x, y, dx, dy, f)\n",
    "#     gabor = (1/(2 * np.pi * dx * dy)) * np.exp(-1/2 * (x ** 2/(dx ** 2) + y ** 2/(dy ** 2))) * M(x,y,f)\n",
    "#     return gabor\n",
    "\n",
    "\n",
    "# # Apply the defined filter to an 8 by 8 block \n",
    "# def block(dx, dy, f):\n",
    "#     feature = np.zeros((8,8))\n",
    "#     for i in range(8):\n",
    "#         for j in range(8):\n",
    "#             feature[i,j] = Gabor((-4+j),(-4+i),dx,dy,f)\n",
    "#     return feature\n",
    "\n",
    "\n",
    "# # The function inputs the two filtered image, calculates mean and std for each block of each channel, \n",
    "# # and returns the desired vector V with all means and stds appended to it.\n",
    "# def get_vector(vector1,vector2):\n",
    "#     feature_vec = []\n",
    "#     # ranges are determined by 48/8 = 6 and 512/8 = 64\n",
    "#     for i in range(6):\n",
    "#         for j in range(64):\n",
    "#             # Loop over each 8 by 8 block to get the feature\n",
    "#             x1 = 8 * i\n",
    "#             x2 = x1 + 8\n",
    "#             y1 = 8 * j\n",
    "#             y2 = y1 + 8\n",
    "            \n",
    "#             # Filtered image block\n",
    "#             c1 = vector1[x1:x2,y1:y2]\n",
    "#             c2 = vector2[x1:x2,y1:y2]\n",
    "            \n",
    "#             c1 = np.abs(c1)\n",
    "#             c2 = np.abs(c2)\n",
    "            \n",
    "#             # Follow the calculation steps in Ma's paper\n",
    "#             # Channel 1 mean and standard deviation\n",
    "#             m1 = np.mean(c1)\n",
    "#             sigma1 = np.mean(np.abs(c1-m1))\n",
    "#             feature_vec.append(m1)\n",
    "#             feature_vec.append(sigma1)\n",
    "            \n",
    "#             # Channel 2 mean and standard deviation\n",
    "#             m2 = np.mean(c2)\n",
    "#             sigma2 = np.mean(np.abs(c2-m2))\n",
    "#             feature_vec.append(m2)\n",
    "#             feature_vec.append(sigma2)\n",
    "            \n",
    "#     return feature_vec\n",
    "\n",
    "# # Inputs a single normalized image\n",
    "# def FeatureExtraction(enhanced_normal):\n",
    "#     f = 2/3\n",
    "#     # Get two channels using the parameters defined in paper\n",
    "#     channel1 = block(3, 1.5, f)\n",
    "#     channel2 = block(4, 1.5, f)\n",
    "    \n",
    "#     feature_vec = []\n",
    "    \n",
    "\n",
    "#     # enhanced_normal has length 64 and enhance_normal has length 512\n",
    "#     # Define a 48 by 512 region as ROI\n",
    "#     ROI = enhanced_normal[:48,:]\n",
    "\n",
    "#     filtered1 = scipy.signal.convolve2d(ROI,channel1,mode='same')\n",
    "#     filtered2 = scipy.signal.convolve2d(ROI,channel2,mode='same')\n",
    "    \n",
    "#     vector = get_vector(filtered1,filtered2)\n",
    "#     feature_vec.append(vector)\n",
    "#     # len(feature_vec) == 1536\n",
    "#     return np.array(feature_vec).flatten()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q5yWPiBAnNV4"
   },
   "source": [
    "# # def slice_per(source, step):\n",
    "# #     return [np.array(source[i::step]).reshape(-1,1536) for i in range(step)]\n",
    "\n",
    "# def LDA(df, target_dim):\n",
    "#   # data = np.array(data)\n",
    "#   mu = np.mean(df['feature'].values,axis=0).reshape(1536,1) # Mean vector mu --> Since the data has been standardized, the data means are zero \n",
    "#   mu_k = []\n",
    "\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       mu_k.append(np.mean(df[df['idx']==idx]['feature'],axis=0))\n",
    "#   mu_k = np.array(mu_k).T\n",
    "\n",
    "#   data_SW = []\n",
    "#   Nc = []\n",
    "#   for i,idx in enumerate(np.unique(df['idx'])):\n",
    "#       a = np.array(np.array(df[df['idx']==idx]['feature'].values.tolist()).reshape(-1, 1536)-mu_k[:,i].reshape(1,1536))\n",
    "#       data_SW.append(np.dot(a.T,a))\n",
    "#       Nc.append(np.sum(df['idx']==idx))\n",
    "#   SW = np.sum(data_SW,axis=0)\n",
    "\n",
    "#   SB = np.dot(Nc*np.array(mu_k-mu),np.array(mu_k-mu).T)\n",
    "#   eigval, eigvec = np.linalg.eig(np.dot(np.linalg.inv(SW),SB))\n",
    "\n",
    "#   eigen_pairs = [[np.abs(eigval[i]),eigvec[:,i]] for i in range(len(eigval))]\n",
    "#   eigen_pairs = sorted(eigen_pairs,key=lambda k: k[0],reverse=True)\n",
    "#   w = np.hstack([eigen_pairs[i][1][:,np.newaxis].real for i in range(target_dim)]) # Select two largest\n",
    "\n",
    "#   # 6. Transform the data with Y=X*w\n",
    "#   # Y = data.dot(w)\n",
    "\n",
    "#   return w\n",
    "\n"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5nDdQfI7qxzi"
   },
   "source": [
    "# images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "\n",
    "# boundary,center = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list = list(zip(boundary, center))\n",
    "\n",
    "# # M = 64\n",
    "# # N = 512\n",
    "# # rows = np.empty((N, M), dtype=object)\n",
    "# # for Y in range(M):\n",
    "# #     for X in range(N):\n",
    "# #         rows[X][Y] = (X, Y)\n",
    "\n"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9Wb6Z2MmeH7N"
   },
   "source": [
    "# normal_out = list(map(lambda x: normalization(x), bc_list))\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OnLEZtlRjx6p"
   },
   "source": [
    "# res=list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), np.array(normal_out.copy())))\n",
    "# sliced_res = list(chunks(res,3))\n",
    "\n",
    "# list_of_dataframes = []\n",
    "# for i, eyes in enumerate(sliced_res):\n",
    "#   # i from 0 to 108\n",
    "#   for j, eye in enumerate(eyes):\n",
    "#     # j from 0 to 2\n",
    "#     degree = [-9,-6,-3,0,3,6,9]\n",
    "#     img_idx = [j]*7\n",
    "#     idx = [i]*7\n",
    "#     df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'data':eye})\n",
    "#     list_of_dataframes.append(df_tmp)\n",
    "# df = pd.concat(list_of_dataframes)\n"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N1SPxUhNq5fd"
   },
   "source": [
    "# df['feature']=df['data'].apply(lambda x: FeatureExtraction(x))"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VJ1Eunbyu3T-"
   },
   "source": [
    "# w = LDA(df, 40)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ev8Rm4ppAawG"
   },
   "source": [],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b3s7_OTbdcOm"
   },
   "source": [
    "# images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "# boundary_test,center_test = IrisLocalization(images_train)\n",
    "\n",
    "# bc_list_test = list(zip(boundary_test, center_test))\n",
    "# normal_out_test = list(map(lambda x: normalization(x), bc_list_test))"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YKlaJUTX1ztY"
   },
   "source": [
    "# sliced_res_test = list(chunks(normal_out_test, 4))\n",
    "\n",
    "# list_of_dataframes_test = []\n",
    "# for i, eyes in enumerate(sliced_res_test):\n",
    "# # i from 0 to 107\n",
    "#     for j, eye in enumerate(eyes):\n",
    "#         # j from 0 to 3\n",
    "#         img_idx = [j]\n",
    "#         idx = [i]\n",
    "#         df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'data':[eye]})\n",
    "#         list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "# df_test = pd.concat(list_of_dataframes_test)\n",
    "# df_test['feature']=df_test['data'].apply(lambda x: FeatureExtraction(x))\n"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aGnY83Synw-R"
   },
   "source": [
    "# clf = LinearDiscriminantAnalysis(n_components=40)\n",
    "# clf.fit(list(df['feature'].values), list(df['idx'].values))\n",
    "# df['new_feature']=df['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))\n",
    "# df_test['new_feature']=df_test['feature'].apply(lambda x: clf.transform(x.reshape(1, -1)))"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6O3nqqIOhW_-"
   },
   "source": [
    "# df_test.head()"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "eZ461gpJ3-of"
   },
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('df_train.pkl', 'wb') as f:\n",
    "#   pickle.dump(df, f)\n",
    "\n",
    "# with open('df_test.pkl', 'wb') as f:\n",
    "#   pickle.dump(df_test, f)"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WWt3a07J3-tU"
   },
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MYIf2SvP2HYO"
   },
   "source": [
    "def compute_dis(test_feature, target_feature, norm):\n",
    "  if norm == 1:\n",
    "    return np.sum(np.abs(test_feature-target_feature))\n",
    "  elif norm == 2:\n",
    "    return np.sum(np.square(test_feature-target_feature))\n",
    "  else:\n",
    "    return np.multiply(test_feature.T,target_feature)/(np.linalg.norm(test_feature)*np.linalg.norm(target_feature))"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "l5sFfsYI4PrB"
   },
   "source": [
    "def get_class(df_train, test_feature, label, norm):\n",
    "  train_templates = df_train[label].values\n",
    "  # print(len(train_templates))\n",
    "  dis = list(map(lambda x: compute_dis(test_feature, x, norm),train_templates))\n",
    "  min_idx = np.argmin(dis)\n",
    "  # print(dis)\n",
    "  # print(min_idx)\n",
    "  return list(df_train['idx'].values)[min_idx]"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e3Zpobb9GYz4"
   },
   "source": [
    "from IrisLocalization import IrisLocalization\n",
    "from IrisNormalization import IrisNormalization, getRotation\n",
    "from ImageEnhancement import ImageEnhancement\n",
    "from FeatureExtraction import FeatureExtraction\n",
    "# from IrisMatching import IrisMatching\n",
    "# from PerformanceEvaluation import PerformanceEvaluation"
   ],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "temeoD3e98IN"
   },
   "source": [],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9CbuOJnM78Qm",
    "outputId": "67c790c2-59f2-4549-962a-3a8b76eb0afe"
   },
   "source": [],
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fred/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/fred/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    }
   ],
   "source": [
    "images_train = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/1/*.bmp'))]\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the training images\n",
    "boundary_train,centers_train=IrisLocalization(images_train)\n",
    "normalized_train=IrisNormalization(boundary_train,centers_train)\n",
    "rotate_train = sum(list(map(lambda p: getRotation(p, [-9,-6,-3,0,3,6,9]), normalized_train.copy())), [])\n",
    "\n",
    "enhanced_train=ImageEnhancement(rotate_train)\n",
    "feature_vector_train=FeatureExtraction(enhanced_train)\n",
    "print(\"Training data processed.\")\n",
    "\n",
    "\n",
    "'''TESTING'''\n",
    "\n",
    "#reading the testing images from the CASIA dataset\n",
    "images_test = [cv2.imread(file) for file in sorted(glob.glob('CASIA Iris Image Database (version 1.0)/*/2/*.bmp'))]\n",
    "\n",
    "#running Localization, Normalization,Enhancement and Feature Extraction on all the testing images\n",
    "boundary_test,centers_test=IrisLocalization(images_test)\n",
    "normalized_test=IrisNormalization(boundary_test,centers_test)\n",
    "enhanced_test=ImageEnhancement(normalized_test)\n",
    "feature_vector_test=FeatureExtraction(enhanced_test)\n",
    "print(\"Testing data processed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1BN9zSk-HGSy",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "sliced_res_train = list(chunks(feature_vector_train,21))\n",
    "\n",
    "list_of_dataframes_train = []\n",
    "for i, eyes in enumerate(sliced_res_train):\n",
    "# i from 0 to 107\n",
    "    sliced_eyes = list(chunks(eyes,7))\n",
    "    for j, eye in enumerate(sliced_eyes):\n",
    "        # j from 0 to 3\n",
    "        degree = [-9,-6,-3,0,3,6,9]\n",
    "        img_idx = [j]*7\n",
    "        idx = [i]*7\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'degree':degree, 'feature': eye })\n",
    "        list_of_dataframes_train.append(df_tmp)\n",
    "df_train = pd.concat(list_of_dataframes_train)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 979
    },
    "id": "cvTumK55HkMV",
    "outputId": "509056d4-e74d-423e-a2ad-ad0054e106dc",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "df_train.head(30)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7QhJi7oRHlQo",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "sliced_res_test = list(chunks(feature_vector_test,4))\n",
    "\n",
    "list_of_dataframes_test = []\n",
    "for i, eyes in enumerate(sliced_res_test):\n",
    "# i from 0 to 107\n",
    "    for j, eye in enumerate(eyes):\n",
    "        # j from 0 to 3\n",
    "        img_idx = [j]\n",
    "        idx = [i]\n",
    "        df_tmp = pd.DataFrame({'idx':idx, 'img_idx':img_idx, 'feature':[np.array(eye)]})\n",
    "        list_of_dataframes_test.append(df_tmp)\n",
    "      \n",
    "df_test = pd.concat(list_of_dataframes_test)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = LDA(n_components=100)\n",
    "clf.fit(list(df_train['feature'].values), list(df_train['idx'].values))\n",
    "df_train['reduced_feature']=df_train['feature'].apply(lambda x: clf.transform(np.array(x).reshape(1, -1)))\n",
    "df_test['reduced_feature']=df_test['feature'].apply(lambda x: clf.transform(np.array(x).reshape(1, -1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UQEVBnOccagi",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "df_test['class']=df_test['reduced_feature'].apply(lambda x: get_class(df_train.copy(), x, 'reduced_feature', 2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "03QDfYnmc5wR",
    "outputId": "680c2ab5-aea7-438b-d7d4-0da76cfbdfdb",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "df_test"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WMPsJoh8c7gY",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "df_test['correct'] = df_test.apply(lambda x: int(x['idx']==x['class']), axis=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnxoUjiicmDd",
    "outputId": "77d0ffe3-9e33-491a-8363-6b399762a8ef",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "sum(df_test['correct'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JxE3SnBFJi20",
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}